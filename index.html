<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Aseem  Baranwal</title>
<meta name="description" content="PhD student at Cheriton School of Computer Science @UWaterloo.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<script src="https://kit.fontawesome.com/51a68d8c36.js" crossorigin="anonymous"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Aseem</span>   Baranwal
      </a>
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications">
                publications
                
              </a>
          </li>
          
          
          <li class="nav-item"><a class="nav-link" href="/assets/pdf/CV.pdf">cv</a></li>
          
          <!-- Blog -->
          <!-- <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li> -->
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5" style="text-align:justify;">
      <div class="post">
  <span class="contact-icon text-center">
  <a href="https://scholar.google.com/citations?user=DPt626YAAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar" style="color:#4285f4;"></i></a>
  <a href="https://github.com/aseemrb" target="_blank" title="GitHub"><i class="fa-brands fa-github" style="color:#333;"></i></a>
  <a href="https://www.linkedin.com/in/aseemrb" target="_blank" title="LinkedIn"><i class="fa-brands fa-linkedin" style="color:#0077b5;"></i></a>
  <a href="https://twitter.com/aseemrb" target="_blank" title="Twitter"><i class="fa-brands fa-x-twitter" style="color:#000;"></i></a>
  <a href="https://t.me/aseemrb" target="_blank" title="Telegram"><i class="fa-brands fa-telegram" style="color:#0088CC;"></i></a>
  <a href="mailto:%68%65%6C%6C%6F@%61%73%65%65%6D%72%62.%6D%65" title="Email"><i class="fa-solid fa-envelope" style="color:#1da1f2;"></i></a>
  <!-- <a href="https://keybase.io/aseemrb" target="_blank" title="Keybase"><i class="fab fa-keybase" style="color:#e68523;"></i></a> -->
  
  
  
</span>

  <article style="padding-top:10px;">
    
    <div class="profile float-right">
      
        <img class="img-fluid" src="/assets/img/ppt.webp" alt="Picture of AB">
      
      
    </div>
    

    <div class="clearfix">
      <p>I’m a Ph.D. student at the <a href="https://cs.uwaterloo.ca/">School of Computer Science</a> at <a href="https://uwaterloo.ca/">UWaterloo</a>, co-advised by two awesome supervisors: Prof <a href="https://scholar.google.ca/citations?user=K-SafJUAAAAJ">Kimon Fountoulakis</a> and Prof <a href="https://aukosh.github.io/">Aukosh Jagannath</a>. I am a part of the <a href="https://opallab.ca/">OpAL Lab</a> and the <a href="https://algcomp.uwaterloo.ca/">A&amp;C group</a>. My interests broadly span machine learning on graphs and high dimensional probability.</p>

<p>I have completed two internships with amazing mentors: The summer of 2023 at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-redmond/">Microsoft Research</a> with <a href="https://www.microsoft.com/en-us/research/people/jstokes/">Jay Stokes</a>, <a href="https://www.linkedin.com/in/mohsenam/">Mohsen Alimomeni</a> and <a href="https://jenneville.github.io/">Jennifer Neville</a> on applications of GNNs in cyber-security; and the fall of 2022 at <a href="https://research.google/teams/graph-mining/">Google Research</a> with <a href="http://www.perozzi.net/">Bryan Perozzi</a>, <a href="http://tsitsul.in/">Anton Tsitsulin</a> and <a href="https://samihaija.github.io/">Sami Abu-El-Haija</a> on scalable GNNs for node-classification.</p>

<p>I received my MMath from UWaterloo, advised by Prof <a href="https://cs.uwaterloo.ca/~shallit/">Jeffrey Shallit</a>, where I worked on algorithmic number theory and combinatorics on words. Prior to that I was an undergrad at <a href="http://iitj.ac.in/">IIT Jodhpur</a>, where I actively contested at the <a href="https://icpc.global/">ACM-ICPC</a> and several <a href="https://ctftime.org/ctf-wtf/">CTFs</a>.</p>

<!-- In my free time I [sketch](), [play board games](), or play my [keys or guitar](). -->
<p>Fun fact: my <a href="https://en.wikipedia.org/wiki/Erd%C5%91s_number">Erdős number</a> is 2 with the path <a href="https://en.wikipedia.org/wiki/Paul_Erd%C5%91s">P. Erdős</a> <a href="http://www.numdam.org/item/JTNB_1991__3_1_43_0/"><i class="fa-solid fa-arrow-right-long"></i></a> <a href="https://cs.uwaterloo.ca/~shallit/">J. Shallit</a> <a href="https://doi.org/10.1016/j.tcs.2021.01.018"><i class="fa-solid fa-arrow-right-long"></i></a> me.</p>

    </div>
    
    
      <div id="news" class="news">
  <h3>news</h3>
  <hr>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row" style="font-weight:bold;">Sep 22, 2023</th>
          <td>
            
              <img class="emoji" title=":fire:" alt=":fire:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png" height="20" width="20"> Our paper <a href="https://openreview.net/forum?id=d1knqWjmNt">Optimality of Message-Passing Architectures for Sparse Graphs</a> is accepted at <a href="https://neurips.cc/">NeurIPS</a>.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row" style="font-weight:bold;">Sep 6, 2023</th>
          <td>
            
              <img class="emoji" title=":fire:" alt=":fire:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png" height="20" width="20"> Our paper <a href="https://dmtcs.episciences.org/12192">Antisquares and Critical Exponents</a> is now available on <a href="https://dmtcs.episciences.org/">DMTCS</a>.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row" style="font-weight:bold;">Aug 15, 2023</th>
          <td>
            
              <img class="emoji" title=":fire:" alt=":fire:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png" height="20" width="20"> Our paper <a href="https://jmlr.org/papers/v24/22-125.html">Graph Attention Retrospective</a> is now available on <a href="https://jmlr.org/">JMLR</a>.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row" style="font-weight:bold;">May 8, 2023</th>
          <td>
            
              <img class="emoji" title=":pray:" alt=":pray:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f64f.png" height="20" width="20"> I received the <a href="https://uwaterloo.ca/graduate-studies-postdoctoral-affairs/current-students/internal-waterloo-awards/presidents-graduate-scholarship">UWaterloo President’s Graduate Scholarship</a> for AY 2023 – 2024.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row" style="font-weight:bold;">May 8, 2023</th>
          <td>
            
              <img class="emoji" title=":pray:" alt=":pray:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f64f.png" height="20" width="20"> I received the <a href="https://osap.gov.on.ca/OSAPPortal/en/A-ZListofAid/PRDR019245.html">Ontario Graduate Scholarship</a> for AY 2023 – 2024.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row" style="font-weight:bold;">Jan 21, 2023</th>
          <td>
            
              <img class="emoji" title=":fire:" alt=":fire:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png" height="20" width="20"> Our paper <a href="https://openreview.net/forum?id=P-73JPgRs0R">Effects of Graph Convolutions in Multilayer Networks</a> is accepted at <a href="https://iclr.cc/">ICLR</a> (spotlight).

            
          </td>
        </tr>
      
        <tr>
          <th scope="row" style="font-weight:bold;">Dec 9, 2022</th>
          <td>
            
              <img class="emoji" title=":metal:" alt=":metal:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f918.png" height="20" width="20"> I am one of the <a href="http://log2022.logconference.org/program-committee/#-top-reviewers">top 20 reviewers at LoG Conference 2022</a>, thanks to the committee!

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
      <div id="publications" class="publications">
  <h3>publications</h3>
  More details on <a href="https://scholar.google.com/citations?user=DPt626YAAAAJ">Google scholar</a>.
  <hr>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-1 abbr">
  
    <abbr class="badge">
    
    <a href="https://neurips.cc/">NeurIPS</a>
    
    </abbr>
  
  </div>
  <div id="optimality-mp:2023" class="col-sm-10">
    <div class="title">
      
        <a href="https://openreview.net/forum?id=d1knqWjmNt">Optimality of Message-Passing Architectures for Sparse Graphs</a>
      
    </div>
    <span class="author">
      
        
        
        
        
        
        
          A. Baranwal, 
        
      
        
        
        
        
          
            
              
              
        
        
        
          <a href="https://scholar.google.ca/citations?user=K-SafJUAAAAJ">K. Fountoulakis</a>, 
        
      
        
        
        
        
          
            
              
              
        
        
        
          <a href="https://www.math.uwaterloo.ca/~a3jagann/">A. Jagannath</a>. 
        
      
      </span>

    <span class="periodical">
    
      Thirty-seventh Conference on Neural Information Processing Systems, 2023
    </span>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
      
      <a href="https://arxiv.org/abs/2305.10391" class="btn btn-sm z-depth-0" role="button">Preprint</a>
      
    
    
    
    
    
      <a href="https://github.com/opallab/optimality-mp-archs-sparse-graphs" class="btn btn-sm z-depth-0" role="button">Code</a>
    
    
      
      <a href="/assets/posters/neurips-2023-optimality-mp.png" class="btn btn-sm z-depth-0" role="button">Poster</a>
      
    
    
    
    
    <!-- <a class="bibtex btn btn-sm z-depth-0" role="button">Bibtex</a> -->
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We study the node classification problem on feature-decorated graphs in the sparse setting, i.e., when the expected degree of a node is \(O(1)\) in the number of nodes, in the fixed-dimensional asymptotic regime, i.e., the dimension of the feature data is fixed while the number of nodes is large. Such graphs are typically known to be locally tree-like. We introduce a notion of Bayes optimality for node classification tasks, called asymptotic local Bayes optimality, and compute the optimal classifier according to this criterion for a fairly general statistical data model with arbitrary distributions of the node features and edge connectivity. The optimal classifier is implementable using a message-passing graph neural network architecture. We then compute the generalization error of this classifier and compare its performance against existing learning methods theoretically on a well-studied statistical model with naturally identifiable signal-to-noise ratios (SNRs) in the data. We find that the optimal message-passing architecture interpolates between a standard MLP in the regime of low graph signal and a typical convolution in the regime of high graph signal. Furthermore, we prove a corresponding non-asymptotic result.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    <!-- <div class="bibtex hidden">
      <pre>@article{optimality-mp:2023,
  selected = {true},
  abbr = {NeurIPS},
  title = {Optimality of Message-Passing Architectures for Sparse Graphs},
  author = {Baranwal, A. and Fountoulakis, K. and Jagannath, A.},
  journal = {Thirty-seventh Conference on Neural Information Processing Systems},
  preprint = {https://arxiv.org/abs/2305.10391},
  url = {https://openreview.net/forum?id=d1knqWjmNt},
  year = {2023},
  poster = {neurips-2023-optimality-mp.png},
  code = {https://github.com/opallab/optimality-mp-archs-sparse-graphs}
}
</pre>
    </div> -->
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-1 abbr">
  
    <abbr class="badge">
    
    <a href="https://jmlr.org/">JMLR</a>
    
    </abbr>
  
  </div>
  <div id="gat-retrospective:2023" class="col-sm-10">
    <div class="title">
      
        <a href="https://jmlr.org/papers/v24/22-125.html">Graph Attention Retrospective</a>
      
    </div>
    <span class="author">
      
        
        
        
        
          
            
              
              
        
        
        
          <a href="https://scholar.google.ca/citations?user=K-SafJUAAAAJ">K. Fountoulakis</a>, 
        
      
        
        
        
        
          
            
              
              
        
        
        
          <a href="https://scholar.google.ca/citations?user=kb4ubhcAAAAJ">A. Levi</a>, 
        
      
        
        
        
        
          
            
              
              
        
        
        
          <a href="https://cs.uwaterloo.ca/~s286yang/">S. Yang</a>, 
        
      
        
        
        
        
        
        
          A. Baranwal, 
        
      
        
        
        
        
          
            
              
              
        
        
        
          <a href="https://www.math.uwaterloo.ca/~a3jagann/">A. Jagannath</a>. 
        
      
      </span>

    <span class="periodical">
    
      Journal of Machine Learning Research  Vol. 241–52, 2023
    </span>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
      
      <a href="https://jmlr.org/papers/v24/22-125.html" class="btn btn-sm z-depth-0" role="button">Preprint</a>
      
    
    
    
    
    
      <a href="https://github.com/opallab/Graph-Attention-Retrospective" class="btn btn-sm z-depth-0" role="button">Code</a>
    
    
    
    
      
      <a href="https://youtu.be/qcRSny2ecZU" class="btn btn-sm z-depth-0" role="button">talk</a>
      
    
    
    <!-- <a class="bibtex btn btn-sm z-depth-0" role="button">Bibtex</a> -->
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Graph-based learning is a rapidly growing sub-field of machine learning with applications in social networks, citation networks, and bioinformatics. One of the most popular models is graph attention networks. They were introduced to allow a node to aggregate information from features of neighbor nodes in a non-uniform way, in contrast to simple graph convolution which does not distinguish the neighbors of a node. In this paper, we theoretically study the behaviour of graph attention networks. We prove multiple results on the performance of the graph attention mechanism for the problem of node classification for a contextual stochastic block model. Here, the node features are obtained from a mixture of Gaussians and the edges from a stochastic block model. We show that in an "easy" regime, where the distance between the means of the Gaussians is large enough, graph attention is able to distinguish inter-class from intra-class edges. Thus it maintains the weights of important edges and significantly reduces the weights of unimportant edges. Consequently, we show that this implies perfect node classification. In the "hard" regime, we show that every attention mechanism fails to distinguish intra-class from inter-class edges. In addition, we show that graph attention convolution cannot (almost) perfectly classify the nodes even if intra-class edges could be separated from inter-class edges. Beyond perfect node classification, we provide a positive result on graph attention’s robustness against structural noise in the graph. In particular, our robustness result implies that graph attention can be strictly better than both the simple graph convolution and the best linear classifier of node features. We evaluate our theoretical results on synthetic and real-world data.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    <!-- <div class="bibtex hidden">
      <pre>@article{gat-retrospective:2023,
  selected = {true},
  abbr = {JMLR},
  title = {Graph Attention Retrospective},
  author = {Fountoulakis, K. and Levi, A. and Yang, S. and Baranwal, A. and Jagannath, A.},
  journal = {Journal of Machine Learning Research},
  year = {2023},
  volume = {24},
  number = {246},
  pages = {1--52},
  preprint = {https://jmlr.org/papers/v24/22-125.html},
  url = {https://jmlr.org/papers/v24/22-125.html},
  code = {https://github.com/opallab/Graph-Attention-Retrospective},
  talk = {https://youtu.be/qcRSny2ecZU}
}
</pre>
    </div> -->
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-1 abbr">
  
    <abbr class="badge">
    
    <a href="https://iclr.cc/">ICLR</a>
    
    </abbr>
  
  </div>
  <div id="effects-gc:2023" class="col-sm-10">
    <div class="title">
      
        <a href="https://openreview.net/forum?id=P-73JPgRs0R">Effects of Graph Convolutions in Multi-layer Networks</a>
      
    </div>
    <span class="author">
      
        
        
        
        
        
        
          A. Baranwal, 
        
      
        
        
        
        
          
            
              
              
        
        
        
          <a href="https://scholar.google.ca/citations?user=K-SafJUAAAAJ">K. Fountoulakis</a>, 
        
      
        
        
        
        
          
            
              
              
        
        
        
          <a href="https://www.math.uwaterloo.ca/~a3jagann/">A. Jagannath</a>. 
        
      
      </span>

    <span class="periodical">
    
      International Conference on Learning Representations, 2023 (spotlight)
    </span>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
      
      <a href="https://arxiv.org/abs/2204.09297" class="btn btn-sm z-depth-0" role="button">Preprint</a>
      
    
    
    
    
    
      <a href="https://github.com/opallab/Effects-of-Graph-Convs-in-Deep-Nets" class="btn btn-sm z-depth-0" role="button">Code</a>
    
    
    
      
      <a href="/assets/pdf/Effects-GC-2023.pdf" class="btn btn btn-sm z-depth-0" role="button">Slides</a>
      
    
    
      
      <a href="https://youtu.be/AtsaBVu-Oq0" class="btn btn-sm z-depth-0" role="button">talk</a>
      
    
    
    <!-- <a class="bibtex btn btn-sm z-depth-0" role="button">Bibtex</a> -->
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We present a rigorous theoretical understanding of the effects of graph convolutions in multi-layer networks. We study these effects through the node classification problem of a non-linearly separable Gaussian mixture model coupled with a stochastic block model. First, we show that a single graph convolution expands the regime of the distance between the means where multi-layer networks can classify the data by a factor of at least \(1/\sqrt[4]∆\), where \(∆\) denotes the expected degree of a node. Second, we show that with a slightly stronger graph density, two graph convolutions improve this factor to at least \(1/\sqrt[4]n\), where \(n\) is the number of nodes in the graph. Finally, we provide both theoretical and empirical insights into the performance of graph convolutions placed in different combinations among the layers of a network, concluding that the performance is mutually similar for all combinations of the placement. We present extensive experiments on both synthetic and real-world data that illustrate our results.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    <!-- <div class="bibtex hidden">
      <pre>@article{effects-gc:2023,
  selected = {true},
  abbr = {ICLR},
  title = {Effects of Graph Convolutions in Multi-layer Networks},
  author = {Baranwal, A. and Fountoulakis, K. and Jagannath, A.},
  journal = {International Conference on Learning Representations},
  preprint = {https://arxiv.org/abs/2204.09297},
  url = {https://openreview.net/forum?id=P-73JPgRs0R},
  slides = {Effects-GC-2023.pdf},
  talk = {https://youtu.be/AtsaBVu-Oq0},
  code = {https://github.com/opallab/Effects-of-Graph-Convs-in-Deep-Nets},
  year = {2023},
  comments = {(spotlight)}
}
</pre>
    </div> -->
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-1 abbr">
  
    <abbr class="badge">
    
    <a href="https://icml.cc/">ICML</a>
    
    </abbr>
  
  </div>
  <div id="graph-conv:2021" class="col-sm-10">
    <div class="title">
      
        <a href="http://proceedings.mlr.press/v139/baranwal21a.html">Graph convolution for Semi-Supervised Classification: Separability and OoD Generalization</a>
      
    </div>
    <span class="author">
      
        
        
        
        
        
        
          A. Baranwal, 
        
      
        
        
        
        
          
            
              
              
        
        
        
          <a href="https://scholar.google.ca/citations?user=K-SafJUAAAAJ">K. Fountoulakis</a>, 
        
      
        
        
        
        
          
            
              
              
        
        
        
          <a href="https://www.math.uwaterloo.ca/~a3jagann/">A. Jagannath</a>. 
        
      
      </span>

    <span class="periodical">
    Proceedings of the 38th International Conference on Machine Learning, Proceedings of Machine Learning Research  Vol. 139684–693, 2021 (spotlight)
    </span>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
      
      <a href="https://arxiv.org/abs/2102.06966" class="btn btn-sm z-depth-0" role="button">Preprint</a>
      
    
    
    
    
    
      <a href="https://github.com/opallab/icml-21-graph-conv/" class="btn btn-sm z-depth-0" role="button">Code</a>
    
    
      
      <a href="/assets/posters/icml-2021-graph-conv.png" class="btn btn-sm z-depth-0" role="button">Poster</a>
      
    
    
      
      <a href="/assets/pdf/Graph-Conv-ICML-2021.pdf" class="btn btn btn-sm z-depth-0" role="button">Slides</a>
      
    
    
      
      <a href="https://youtu.be/2IyzIIwmQCo" class="btn btn-sm z-depth-0" role="button">talk</a>
      
    
    
    <!-- <a class="bibtex btn btn-sm z-depth-0" role="button">Bibtex</a> -->
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We study the classification of a mixture of Gaussians, where the data corresponds to the node attributes of a stochastic block model. We show that graph convolution extends the regime in which the data is linearly separable by a factor of roughly \(1/\sqrt D\), where \(D\) is the expected degree of a node, as compared to the mixture model data on its own. Furthermore, we find that the linear classifier obtained by minimizing the cross-entropy loss after the graph convolution generalizes to out-of-distribution data where the unseen data can have different intra- and inter-class edge probabilities from the training data.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    <!-- <div class="bibtex hidden">
      <pre>@inproceedings{graph-conv:2021,
  selected = {true},
  abbr = {ICML},
  title = {Graph convolution for Semi-Supervised Classification: Separability and OoD Generalization},
  author = {Baranwal, A. and Fountoulakis, K. and Jagannath, A.},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning},
  pages = {684--693},
  year = {2021},
  editor = {Meila, Marina and Zhang, Tong},
  volume = {139},
  series = {Proceedings of Machine Learning Research},
  month = {18--24 Jul},
  publisher = {Proceedings of Machine Learning Research},
  preprint = {https://arxiv.org/abs/2102.06966},
  url = {http://proceedings.mlr.press/v139/baranwal21a.html},
  slides = {Graph-Conv-ICML-2021.pdf},
  code = {https://github.com/opallab/icml-21-graph-conv/},
  talk = {https://youtu.be/2IyzIIwmQCo},
  poster = {icml-2021-graph-conv.png},
  comments = {(spotlight)}
}
</pre>
    </div> -->
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-1 abbr">
  
    <abbr class="badge">
    
    <a href="https://dmtcs.episciences.org/">DMTCS</a>
    
    </abbr>
  
  </div>
  <div id="antisq-crit-exp:2023" class="col-sm-10">
    <div class="title">
      
        <a href="http://dmtcs.episciences.org/12192">Antisquares and Critical Exponents</a>
      
    </div>
    <span class="author">
      
        
        
        
        
        
        
          A. Baranwal, 
        
      
        
        
        
        
          
            
              
              
        
        
        
          <a href="https://ion.uwinnipeg.ca/~currie/">J. Currie</a>, 
        
      
        
        
        
        
          
            
              
              
        
        
        
          <a href="https://faculty.tru.ca/lmol/">L. Mol</a>, 
        
      
        
        
        
        
          
            
              
              
        
        
        
          <a href="https://www.lirmm.fr/~ochem/">P. Ochem</a>, 
        
      
        
        
        
        
          
            
              
              
        
        
        
          <a href="https://ion.uwinnipeg.ca/~nrampers/">N. Rampersad</a>, 
        
      
        
        
        
        
          
            
              
              
        
        
        
          <a href="https://cs.uwaterloo.ca/~shallit/">J. Shallit</a>. 
        
      
      </span>

    <span class="periodical">
    
      Discrete Mathematics &amp; Theoretical Computer Science  Vol. 25:2, 2023
    </span>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
      
      <a href="https://arxiv.org/abs/2209.09223" class="btn btn-sm z-depth-0" role="button">Preprint</a>
      
    
    
    
    
    
    
    
    
    
    <!-- <a class="bibtex btn btn-sm z-depth-0" role="button">Bibtex</a> -->
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The complement \(\bar{x}\) of a binary word \(x\) is obtained by changing each \(0\) in \(x\) to \(1\) and vice versa. An antisquare is a nonempty word of the form \(x\bar{x}\). In this paper, we study infinite binary words that do not contain arbitrarily large antisquares. For example, we show that the repetition threshold for the language of infinite binary words containing exactly two distinct antisquares is \((5+\sqrt5)/2\). We also study repetition thresholds for related classes, where "two" in the previous sentence is replaced by a large number. We say a binary word is good if the only antisquares it contains are \(01\) and \(10\). We characterize the minimal antisquares, that is, those words that are antisquares but all proper factors are good. We determine the growth rate of the number of good words of length \(n\) and determine the repetition threshold between polynomial and exponential growth for the number of good words.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    <!-- <div class="bibtex hidden">
      <pre>@article{antisq-crit-exp:2023,
  abbr = {DMTCS},
  title = {{Antisquares and Critical Exponents}},
  author = {Baranwal, A. and Currie, J. and Mol, L. and Ochem, P. and Rampersad, N. and Shallit, J.},
  journal = {Discrete Mathematics \& Theoretical Computer Science},
  volume = {{25:2}},
  preprint = {https://arxiv.org/abs/2209.09223},
  url = {http://dmtcs.episciences.org/12192},
  year = {2023}
}
</pre>
    </div> -->
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-1 abbr">
  
    <abbr class="badge">
    
    <a href="https://www.sciencedirect.com/journal/theoretical-computer-science">TCS</a>
    
    </abbr>
  
  </div>
  <div id="ostr:2020" class="col-sm-10">
    <div class="title">
      
        <a href="https://doi.org/10.1016/j.tcs.2021.01.018">Ostrowski-Automatic Sequences: Theory and Applications</a>
      
    </div>
    <span class="author">
      
        
        
        
        
        
        
          A. Baranwal, 
        
      
        
        
        
        
          
            
              
              
        
        
        
          <a href="https://www.semanticscholar.org/author/Luke-Schaeffer/34772472">L. Schaeffer</a>, 
        
      
        
        
        
        
          
            
              
              
        
        
        
          <a href="https://cs.uwaterloo.ca/~shallit/">J. Shallit</a>. 
        
      
      </span>

    <span class="periodical">
    
      Theoretical Computer Science  Vol. 858122-142, 2021
    </span>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
    
    
    
    
      <a href="https://github.com/aseemrb/walnut" class="btn btn-sm z-depth-0" role="button">Code</a>
    
    
    
    
    
    <!-- <a class="bibtex btn btn-sm z-depth-0" role="button">Bibtex</a> -->
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We extend the notion of \(k\)-automatic sequences to Ostrowski-automatic sequences, and develop a procedure to computationally decide certain combinatorial and enumeration questions about such sequences that can be expressed as predicates in first-order logic. Our primary contribution is the design and implementation of an adder recognizing addition in a generalized Ostrowski numeration system. We also provide applications of our work to several topics in combinatorics on words.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    <!-- <div class="bibtex hidden">
      <pre>@article{ostr:2020,
  abbr = {TCS},
  title = {Ostrowski-Automatic Sequences: Theory and Applications},
  author = {Baranwal, A. and Schaeffer, L. and Shallit, J.},
  journal = {Theoretical Computer Science},
  volume = {858},
  pages = {122-142},
  year = {2021},
  issn = {0304-3975},
  doi = {https://doi.org/10.1016/j.tcs.2021.01.018},
  url = {https://doi.org/10.1016/j.tcs.2021.01.018},
  code = {https://github.com/aseemrb/walnut},
  publisher = {Elselvier}
}
</pre>
    </div> -->
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-1 abbr">
  
    <abbr class="badge">
    
    THESIS
    
    </abbr>
  
  </div>
  <div id="baranwal:2020" class="col-sm-10">
    <div class="title">
      
        <a href="https://hdl.handle.net/10012/15845">Decision Algorithms for Ostrowski-Automatic Sequences</a>
      
    </div>
    <span class="author">
      
        
        
        
        
        
        
          A. Baranwal. 
        
      
      </span>

    <span class="periodical">
    
      MMath Thesis, Univeristy of Waterloo, 2020
    </span>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
    
    
    
    
    
    
      
      <a href="/assets/pdf/Ostrowski-Decision-Algorithms.pdf" class="btn btn btn-sm z-depth-0" role="button">Slides</a>
      
    
    
    
    <!-- <a class="bibtex btn btn-sm z-depth-0" role="button">Bibtex</a> -->
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We extend the notion of automatic sequences to a broader class, the Ostrowski-automatic sequences. We develop a procedure for computationally deciding certain combinatorial and enumeration questions about such sequences that can be expressed as predicates in first-order logic. In Chapter 1, we begin with topics and ideas that are preliminary to this work, including a small introduction to non-standard positional numeration systems and the relationship between words and automata. In Chapter 2, we define the theoretical foundations for recognizing addition in a generalized Ostrowski numeration system and formalize the general theory that develops our decision procedure. Next, in Chapter 3, we show how to implement these ideas in practice, and provide the implementation as an integration to the automatic theorem-proving software package – Walnut. Further, we provide some applications of our work in Chapter 4. These applications span several topics in combinatorics on words, including repetitions, pattern-avoidance, critical exponents of special classes of words, properties of Lucas words, and so forth. Finally, we close with open problems on decidability and higher-order numeration systems and discuss future directions for research.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    <!-- <div class="bibtex hidden">
      <pre>@article{baranwal:2020,
  abbr = {THESIS},
  title = {Decision Algorithms for Ostrowski-Automatic Sequences},
  author = {Baranwal, A.},
  journal = {MMath Thesis, Univeristy of Waterloo},
  year = {2020},
  url = {https://hdl.handle.net/10012/15845},
  slides = {Ostrowski-Decision-Algorithms.pdf}
}
</pre>
    </div> -->
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-1 abbr">
  
    <abbr class="badge">
    
    <a href="https://link.springer.com/conference/cwords">WORDS</a>
    
    </abbr>
  
  </div>
  <div id="rich:2019" class="col-sm-10">
    <div class="title">
      
        <a href="https://doi.org/10.1007/978-3-030-28796-2_7">Repetitions in infinite palindrome-rich words</a>
      
    </div>
    <span class="author">
      
        
        
        
        
        
        
          A. Baranwal, 
        
      
        
        
        
        
          
            
              
              
        
        
        
          <a href="https://cs.uwaterloo.ca/~shallit/">J. Shallit</a>. 
        
      
      </span>

    <span class="periodical">
    Combinatorics on Words, Lecture Notes in Computer Science  Vol. 1168293–105, 2019
    </span>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
      
      <a href="https://arxiv.org/abs/1904.10028" class="btn btn-sm z-depth-0" role="button">Preprint</a>
      
    
    
    
    
    
    
    
      
      <a href="/assets/pdf/Repetitions-Rich-Words.pdf" class="btn btn btn-sm z-depth-0" role="button">Slides</a>
      
    
    
    
    <!-- <a class="bibtex btn btn-sm z-depth-0" role="button">Bibtex</a> -->
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Rich words are those containing the maximum possible number of distinct palindromes. Several characteristic properties of rich words have been studied; yet the analysis of repetitions in rich words still involves some interesting open problems. We consider lower bounds on the repetition threshold of infinite rich words over 2- and 3-letter alphabets, and construct a candidate infinite rich word over the alphabet \(\Sigma_2=\{0,1\}\) with a small critical exponent of \(2+\sqrt2/2\). This represents the first progress on an open problem of Vesti from 2017.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    <!-- <div class="bibtex hidden">
      <pre>@inproceedings{rich:2019,
  abbr = {WORDS},
  title = {Repetitions in infinite palindrome-rich words},
  author = {Baranwal, A. and Shallit, J.},
  booktitle = {Combinatorics on Words},
  series = {Lecture Notes in Computer Science},
  volume = {11682},
  pages = {93--105},
  url = {https://doi.org/10.1007/978-3-030-28796-2_7},
  preprint = {https://arxiv.org/abs/1904.10028},
  slides = {Repetitions-Rich-Words.pdf},
  year = {2019},
  organization = {Springer}
}
</pre>
    </div> -->
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-1 abbr">
  
    <abbr class="badge">
    
    <a href="https://link.springer.com/conference/cwords">WORDS</a>
    
    </abbr>
  
  </div>
  <div id="balanced:2019" class="col-sm-10">
    <div class="title">
      
        <a href="https://doi.org/10.1007/978-3-030-28796-2_6">Critical exponent of infinite balanced words via the Pell number system</a>
      
    </div>
    <span class="author">
      
        
        
        
        
        
        
          A. Baranwal, 
        
      
        
        
        
        
          
            
              
              
        
        
        
          <a href="https://cs.uwaterloo.ca/~shallit/">J. Shallit</a>. 
        
      
      </span>

    <span class="periodical">
    Combinatorics on Words, Lecture Notes in Computer Science  Vol. 1168280–92, 2019
    </span>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
      
      <a href="https://arxiv.org/abs/1902.00503" class="btn btn-sm z-depth-0" role="button">Preprint</a>
      
    
    
    
    
    
    
    
    
    
    <!-- <a class="bibtex btn btn-sm z-depth-0" role="button">Bibtex</a> -->
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In a recent paper of Rampersad et al., the authors conjectured that the smallest possible critical exponent of an infinite balanced word over a \(5\)-letter alphabet is \(3/2\). We prove this result, using a formulation of first-order logic, the Pell number system, and a machine computation based on finite-state automata.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    <!-- <div class="bibtex hidden">
      <pre>@inproceedings{balanced:2019,
  abbr = {WORDS},
  title = {Critical exponent of infinite balanced words via the Pell number system},
  author = {Baranwal, A. and Shallit, J.},
  booktitle = {Combinatorics on Words},
  series = {Lecture Notes in Computer Science},
  volume = {11682},
  pages = {80--92},
  url = {https://doi.org/10.1007/978-3-030-28796-2_6},
  preprint = {https://arxiv.org/abs/1902.00503},
  year = {2019},
  organization = {Springer}
}
</pre>
    </div> -->
  </div>
</div>
</li>
</ol>
</div>

<!-- bibliography -f papers -q @*[selected=true]* -->
    
  </article>

</div>

    </div>

  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


  <br>
</html>
